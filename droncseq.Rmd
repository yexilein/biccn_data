---
title: "Formatting and QC for DroNc-seq data"
output: html_notebook
---

# Looking at the data

We will look at the data from the cortex by the Regev lab. According to the reports, the dataset we are looking at contains 172 quality cells (containing enough different genes).

The dataset contains BAM data, reads DGE data (?) and UMI DGE data (?). Let's try to have a look. All directories contain an archive with similar name. The only difference is that the name mentions that something has been corrected and the archive keeps getting smaller. I would assume that the UMI directory contains the relevant data after sorting out cells with too little information.

```{r}
read_dronc_matrix <- function(gz_file, gene_column = "GENE") {
  result <- read.table(gzfile(gz_file), header = TRUE)
  rownames(result) <- result[[gene_column]]
  return(result[-1])  
}
```


```{r}
data_dir <- "~/work/data/BICCN_18_05_21/Macosko_Regev/regev_comparison_snrnaseq_10x_drop/2017_09_30_droncseq/droncseq_cortex1/"
gene_counts <- read_dronc_matrix(file.path(
  data_dir, "UMI_DGE/reads.droncseq_cortex1_R1.fastq_bq10_star_corrected.umi.dge.txt.gz"
))
```

So what do we have?

```{r}
dim(gene_counts)
head(gene_counts)
```

We actually have 853 cells byt only 16736 genes. I do not see any information on introns vs exons. Gene names are different from 10x, the first genes listed seem to be ncRNAs. 

```{r}
rownames(gene_counts)
```

This dataset seem to use NCBI identifiers, while 10x was annotated using ensembl identifiers. Some mapping will be necessary.

The selected number of cells selected is not very clear, one report mentions 853 cells based on reads, the other 172 cells. Let's have a look at the other sets for comparison:

```{r}
reads_data <- read.table(gzfile(file.path(
  data_dir, "bam_reads/reads.droncseq_cortex1_R1.fastq_bq10_star.reads.txt.gz"
)))
corrected_data <- read_dronc_matrix(file.path(
  data_dir, "reads_DGE/reads.droncseq_cortex1_R1.fastq_bq10_star_corrected.reads.dge.txt.gz"
))
```

```{r}
dim(reads_data)
dim(corrected_data)
dim(gene_counts)
```

```{r}
head(reads_data)
```

The reads part contains some kind of raw data. I am not exactly sure what the second colum represents. Perhaps cell barcodes?

```{r}
head(corrected_data)
```
```{r}
all(colnames(corrected_data) == reads_data[seq(dim(corrected_data)[2]), 2])
```

So the reads data seem to indicate how many reads per barcode were sequenced. This certainly serves as a way to select relevant cells. The corrected data only contains data for the 853 most interesting cells.

```{r}
head(gene_counts)
```

I imagine that gene_counts is based on UMI while corrected counts is based on reads, as can be judged by the second column, where 18 and 65 both map to 1 UMI in the end.

I don't know where the actual reads are or how they were mapped to genes (introns vs exons).


# Formatting multiple datasets

Now that we know what a dataset looks like, we can try to load all datasets:

```{r}
data_dir <- "~/work/data/BICCN_18_05_21/Macosko_Regev/regev_comparison_snrnaseq_10x_drop/2017_09_30_droncseq/"
subdirectories <- list.dirs(data_dir, recursive = FALSE)
gz_file_name <- function(dir_name) {
  filename <- paste0("UMI_DGE/reads.", basename(dir_name), "_R1.fastq_bq10_star_corrected.umi.dge.txt.gz")
  return(file.path(dir_name, filename))
}
gene_count_list <- lapply(subdirectories, function(d) read_dronc_matrix(gz_file_name(d)))
```

```{r}
length(gene_count_list)
```
Check for consistency in gene names

```{r}
source("dataset_fusion.R")
check_rowname_consistency(gene_count_list)
```

So they are not consistent...

```{r}
lapply(gene_count_list, dim)
```

```{r}
lapply(gene_count_list, function(x) head(rownames(x)))
```

At least it looks like they use the same identifiers. Maybe they removed all zero genes?

```{r}
gene_statistics <- data.frame(number_transcripts = apply(gene_count_list[[2]], 1, sum))
```

```{r}
library(tidyverse)
ggplot(gene_statistics) + geom_histogram(aes(number_transcripts)) + scale_x_continuous(trans="log1p")
sum(gene_statistics$number_transcripts == 0)
```

Okay so that is actually a plausible explanation. This means that we can join the datasets by filling in missing values with zeros.

```{r}
test <- merge(gene_count_list[[1]], gene_count_list[[2]], by = "row.names", all = TRUE)
rownames(test) <- test$Row.names
test <- subset(test, select = -Row.names)
```

```{r}
dim(test)
length(unique(c(rownames(gene_count_list[[1]]), rownames(gene_count_list[[2]]))))
dim(gene_count_list[[1]])[2] + dim(gene_count_list[[2]])[2]
```

```{r}
sum(is.na(test))
```

Missing values were replaced by NAs as expected.

Let us try various options to fuse datasets.

  1. merge
  1. with tidyverse
  1. by hand (using match?)

Here is the merge solution:

```{r}
fuse_dronc_merge <- function(datasets) {
  datasets <- lapply(datasets, function(d) {d$gene_name <- rownames(d); return(d)})
  return(Reduce(function(x, y) merge(x, y, by = "gene_name", all = TRUE), datasets))
}
test <- fuse_dronc_merge(gene_count_list)
dim(test)
```

Here is the tidyverse solution:

```{r}
library(tidyverse)
library(reshape2)
melt_dronc <- function(dronc_data) {
  result <- melt(as.matrix(dronc_data))
  colnames(result) <- c("gene", "sample", "count")
  return(result)
}
molten_counts <- lapply(gene_count_list, melt_dronc)
test <- Reduce(function(x,y) full_join(x, y, by = "gene"), molten_counts)
```
Tidy data is probably too memory intesive to be really viable...